{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Jupyter Notebook to Convert H5 Files to cropped KLBs for processing\n",
    "For help, contact Abhishek Biswas (ab50@princeton.edu)\n",
    "The first cell below is to be used to specify user inputs and some basic validation checks. The checks will fail of something is wrong with the inputs. \n",
    "\n",
    "## Step 1: Setup the inputs for the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### USER INPUTS HERE #################################################\n",
    "\n",
    "# Either slash / or \\ will work. ONLY do not end with a \\\n",
    "experiment_path = r'Z:\\Maddy\\230623_YAP_Cdx2_high_settings_at_8cell\\2023-06-23_170300' # NOTHING will be changed in this path.\n",
    "\n",
    "output_path = r'Z:\\Abhishek\\processed'                           # ALL output will appear here.\n",
    "\n",
    "channel_jumps = [2, 1, 1]                              # Specify the timepoint jump for the 3 channels.\n",
    "\n",
    "MergeStacks = True                                     # Merge and re-number the stacks from multiple timeseries\n",
    "\n",
    "SkipFirstSeries = True                                 # Skip the first timeseries in the merge \n",
    "\n",
    "channel_base_name1 = 'Cam_Long_'\n",
    "channel_base_name2 = 'Cam_Short_'\n",
    "\n",
    "timestep = 900 #timestep for aquisition in seconds\n",
    "\n",
    "foreground = True #is the only thing running? If no, set to False.\n",
    "\n",
    "isDotH5 = False #True #is this file in the old .h5 format rather than .lux.h5? True = .h5 False = .lux.h5\n",
    "\n",
    "ZtoDisplay = 15 # Which Z plane do we want to load to check?\n",
    "\n",
    "######################### END USER INPUTS ##################################################\n",
    "import os\n",
    "\n",
    "if not os.path.isdir(experiment_path):\n",
    "    raise ValueError('Error! Not a correct directory path {!r}'.format(experiment_path))\n",
    "    \n",
    "if not os.path.isdir(output_path):\n",
    "    raise ValueError('Error! Not a correct directory path {!r}'.format(output_path))\n",
    "    \n",
    "out_experiment_path = os.path.join(output_path, os.path.basename(experiment_path))\n",
    "\n",
    "if out_experiment_path == os.path.normpath(experiment_path):\n",
    "    print('!!!WARNING!!!')\n",
    "    print('!!!WARNING!!!')\n",
    "    print('The output directory is being placed in the same path the original expriment directory.')\n",
    "    print('This is NOT advisable. This will co-mingle the H5 and the KLB files!')\n",
    "    print('!!!WARNING!!!')\n",
    "    print('!!!WARNING!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Gather all the relevant H5 files to process and display 1 example\n",
    "\n",
    "**You cannot skip Step 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found total of 0 image files to process...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m all_H5s \u001b[38;5;241m=\u001b[39m get_all_h5(experiment_path, isDotH5)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound total of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m image files to process...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(all_H5s)))\n\u001b[1;32m---> 48\u001b[0m currentH5 \u001b[38;5;241m=\u001b[39m \u001b[43mall_H5s\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrying to show: \u001b[39m\u001b[38;5;124m'\u001b[39m, currentH5)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import h5py\n",
    "import numpy\n",
    "from PIL import Image , ImageFilter\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def check_cam_file(filename: str, isDotH5: bool) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the given filename is a valid camera file, i.e., if it ends with '.lux.h5' and\n",
    "    starts with either 'channel_base_name1' or 'channel_base_name2', and False otherwise.\n",
    "\n",
    "    Args:\n",
    "    - filename (str): The name of the file to be checked.\n",
    "    - isDotH5 (bool): Flag to check if it's .h5 or .lux.h5\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the file is a valid camera file, False otherwise.\n",
    "    \"\"\"\n",
    "    ext_str = '.lux.h5'\n",
    "    if isDotH5:\n",
    "        ext_str = '.h5'\n",
    "    if filename.endswith(ext_str) and (filename.startswith(channel_base_name1) or filename.startswith(channel_base_name2)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_all_h5(experiment_path:str, isDotH5: bool) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of all the '.lux.h5' files in the given experiment path and its subdirectories.\n",
    "\n",
    "    Args:\n",
    "    - experiment_path (str): The path to the experiment directory.\n",
    "    - isDotH5 (bool): Flag to check if it's .h5 or .lux.h5\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of strings representing the paths to all the '.lux.h5' files in the given experiment path and\n",
    "            its subdirectories.\n",
    "    \"\"\"\n",
    "    result = [os.path.join(dp, f)\n",
    "        for dp, dn, filenames in os.walk(experiment_path)\n",
    "        for f in filenames if check_cam_file(f, isDotH5)]\n",
    "    return result\n",
    "\n",
    "all_H5s = get_all_h5(experiment_path, isDotH5)\n",
    "print('Found total of {0} image files to process...'.format(len(all_H5s)))\n",
    "currentH5 = all_H5s[0]\n",
    "try:\n",
    "    print('Trying to show: ', currentH5)\n",
    "    fileIn2 = h5py.File(currentH5, 'r') #open current channel 2 H5 file in read mode.\n",
    "except IOError:\n",
    "    print('Failed to load file: ' + currentH5)\n",
    "    print('Check that your path-to-file is correct.')\n",
    "    print('Did you remember to include the top and bottom-most directories?')\n",
    "    print('Are we .h5 or .lux.h5? Ensure that the parameter is set correctly:')\n",
    "    print('True = .h5; False = .lux.h5')\n",
    "    pass\n",
    "fileAttributes = fileIn2[('/')]\n",
    "fileAttributes = h5py.AttributeManager(fileAttributes)\n",
    "dataset = fileIn2[('Data')]\n",
    "dataAttributes = h5py.AttributeManager(dataset)\n",
    "dataset = fileIn2[('Data')]\n",
    "dataset = numpy.ascontiguousarray(dataset)\n",
    "f = plt.figure(figsize = (10,10))\n",
    "plt.imshow(dataset[ZtoDisplay,:,:])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Convert the H5 files to KLB\n",
    "\n",
    "Run both the cells. This will take a while to run. Try to have fewer other programs things running on the computer.\n",
    "\n",
    "**If you ran Step 3 before already, you can jump to step 4 with the same input paths.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Automated Script Begins for KLB Conversion ###\n",
    "import pyklb # this is our .klb management package\n",
    "import scipy # this imports all of science python. We'll probably use something from it. \n",
    "from scipy import ndimage\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def PARKLBWrite(currentfilenum: int):\n",
    "    \"\"\"\n",
    "    Writes a KLB file and produces a maximum intensity projection (MIP) of the file in PNG format.\n",
    "\n",
    "    Args:\n",
    "        currentfilenum (int): An integer representing the current file number.\n",
    "\n",
    "    Returns:\n",
    "        int: Returns 0 if the function is not able to load the current H5 file.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        currentH51 = all_H5s[currentfilenum]\n",
    "        fileIn1 = h5py.File(currentH51, 'r') #open current channel 1 H5 file in read mode.\n",
    "        dataset1 = fileIn1[\"Data\"][:]\n",
    "    except:\n",
    "        print('failed to load ' + currentH51)\n",
    "        return 0\n",
    "    \n",
    "    klbBlobCH1 = numpy.ascontiguousarray(dataset1)\n",
    "    \n",
    "    dir_path = os.path.dirname(currentH51)\n",
    "    filename = os.path.splitext(os.path.basename(currentH51))[0]\n",
    "    out_dir_path = dir_path.replace(os.path.normpath(experiment_path), os.path.join(output_path, os.path.basename(experiment_path)))\n",
    "    mip_dir_path = os.path.join(out_dir_path, 'MIPs')\n",
    "    if not os.path.isdir(out_dir_path):\n",
    "        try: \n",
    "            os.makedirs(out_dir_path)\n",
    "            os.makedirs(mip_dir_path)\n",
    "        except OSError:\n",
    "            pass\n",
    "    output_to_file = os.path.join(out_dir_path, filename+'.klb')\n",
    "    MetaDataString1 = ''\n",
    "    pyklb.writefull(numpy.ascontiguousarray(klbBlobCH1), output_to_file, numThreads, pixel_spacing, MetaDataString1)\n",
    "\n",
    "    # Prodice the MIP in png format\n",
    "    mip_to_file = os.path.join(mip_dir_path, 'MIP_' + filename + '.png')\n",
    "    mipOut = numpy.amax(numpy.ascontiguousarray(klbBlobCH1),0)\n",
    "    mipIMG = Image.fromarray(mipOut)\n",
    "    mipIMG.save(mip_to_file)\n",
    "    return 1\n",
    "\n",
    "# Setup required parameters for KLB conversion \n",
    "zspace, yspace, xspace = dataAttributes[('element_size_um')]\n",
    "cspace = 1\n",
    "pixel_spacing = [timestep, cspace, zspace, yspace, xspace]\n",
    "zmax , xmax , ymax = dataset.shape\n",
    "\n",
    "out_experiment_path = os.path.join(output_path, os.path.basename(experiment_path))\n",
    "print('Starting parallel conversion process. Output directory: ' + out_experiment_path)\n",
    "# Initiate KLB conversion in parallel for all the H5 files\n",
    "if foreground:\n",
    "    numThreads= 10 #how many threads do you want pyklb to have access to during the write step\n",
    "    results = Parallel(n_jobs=10, verbose = 50, backend = \"threading\")(map(delayed(PARKLBWrite),range(0,len(all_H5s))))\n",
    "else:\n",
    "    numThreads= 5 #how many threads do you want pyklb to have access to during the write step\n",
    "    results = Parallel(n_jobs=2, verbose = 50, backend = \"threading\")(map(delayed(PARKLBWrite),range(0,len(all_H5s))))\n",
    "\n",
    "with open(os.path.join(out_experiment_path,'parameterData.csv'), 'w') as csvfile:\n",
    "    fieldnames = ['param', 'value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    #px parameters\n",
    "    writer.writerow({'param': '-', 'value' : '-'})\n",
    "    writer.writerow({'param': 'timestep', 'value' : 'timestep'})\n",
    "    writer.writerow({'param': 'z step', 'value': zspace})\n",
    "    writer.writerow({'param': 'pixelSize', 'value': xspace})\n",
    "    #timestep, cspace, zspace, yspace, xspace\n",
    "import shutil\n",
    "nb_full_path = os.path.join(os.getcwd(), nb_name)\n",
    "shutil.copy2(nb_full_path , os.path.join(out_experiment_path , 'scriptUsed.ipynb'))\n",
    "print('Initial KLB Conversion Task Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Merge the Stacks and Re-number KLBs\n",
    "\n",
    "Check if you have correctly setup the `channel_jumps` parameter. \n",
    "\n",
    "**If you ran Step 4 successfully before, you can jump to step 5 with the same input paths. You can't however skip Step 4 even if you have one acquisition folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging stacks in run: 2023-01-19_190404\n",
      "Merging stacks in run: 2023-01-19_194838\n",
      "Merging stacks in run: 2023-01-19_233012\n",
      "Merging the stacks is complete!\n",
      "Merged files are here: Z:\\Abhishek\\processed\\230119_YAP_Sox2_memb-GFP_H2B-miRFP720\\merged\n",
      "Deleting the acqusition stack:\n"
     ]
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "\n",
    "# Initialized again so that this step could be run if Step 3 is being skipped \n",
    "out_experiment_path = os.path.join(output_path, os.path.basename(experiment_path))\n",
    "\n",
    "def get_filename_components(image_file_str: str) -> list:\n",
    "    \"\"\"\n",
    "    Extracts components from a filename string.\n",
    "\n",
    "    Args:\n",
    "        image_file_str (str): A string representing the filename of an image file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of three components extracted from the filename string, namely:\n",
    "              - file_prefix: A string representing the prefix of the filename, obtained by removing the\n",
    "                file extension and the time index.\n",
    "              - file_ext: A string representing the file extension (fixed value of \".lux.klb\").\n",
    "              - time_index: An integer representing the time index extracted from the filename.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    file_ext = \".lux.klb\"\n",
    "    file_base = image_file_str.replace(file_ext,'')\n",
    "    file_tok_list = file_base.split('_')\n",
    "    file_prefix = '_'.join(file_tok_list[0:-1])\n",
    "    time_index = int(file_tok_list[-1])\n",
    "    return file_prefix, file_ext, time_index\n",
    "\n",
    "def file_timepoint_dict(dir_path: str)->dict:\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping time indices to a list of files that have that time index.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): A string representing the path to a directory containing image files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are integers representing time indices, and the values are lists\n",
    "              of strings representing filenames that have that time index.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    time_file_dict = {}\n",
    "    for fname in os.listdir(dir_path):\n",
    "        f_path = os.path.join(dir_path,fname)\n",
    "        if os.path.isfile(f_path):\n",
    "            file_prefix, file_ext, time_index = get_filename_components(fname)\n",
    "            if time_index in time_file_dict:\n",
    "                time_file_dict[time_index].append(fname)\n",
    "            else:\n",
    "                time_file_dict[time_index] = [fname]\n",
    "    return time_file_dict\n",
    "\n",
    "def extract_channel_id(stack_dir_name) -> int:\n",
    "    \"\"\"\n",
    "    Extracts the channel ID from a stack directory name.\n",
    "\n",
    "    Args:\n",
    "        stack_dir_name (str): A string representing the name of a stack directory.\n",
    "\n",
    "    Returns:\n",
    "        int: An integer representing the channel ID extracted from the stack directory name.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the stack directory name is not in the correct format (i.e., does not contain the\n",
    "                    string 'channel' followed by an integer).\n",
    "    \"\"\"\n",
    "\n",
    "    stack_tok = stack_dir_name.split('_')\n",
    "    try:\n",
    "        return int(stack_tok[stack_tok.index('channel') + 1])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise ValueError('Error! Stack directory not correct format{!r}'.format(stack_dir_name))\n",
    "\n",
    "# Remove merged directories if there are any\n",
    "merged_experiment_path = os.path.join(out_experiment_path, 'merged')\n",
    "if os.path.isdir(merged_experiment_path):\n",
    "    shutil.rmtree(merged_experiment_path)\n",
    "\n",
    "run_dirs = next(os.walk(out_experiment_path))[1]\n",
    "run_dict = {}\n",
    "for run in run_dirs:\n",
    "    run_dir_tok = run.split(sep='_')\n",
    "    if len(run_dir_tok) == 2:\n",
    "        rid_id = run_dir_tok[1]\n",
    "        run_dict[rid_id] = run\n",
    "\n",
    "# Sort the runs\n",
    "sorted_runs = list(run_dict.keys())\n",
    "sorted_runs.sort()\n",
    "\n",
    "# Remove the first run dictionary\n",
    "if len(run_dict) > 1 and SkipFirstSeries:\n",
    "    run_dict.pop(sorted_runs[0])\n",
    "    sorted_runs.pop(0)\n",
    "    \n",
    "# Create merging directory\n",
    "if not os.path.isdir(merged_experiment_path):\n",
    "    os.makedirs(merged_experiment_path)\n",
    "\n",
    "# Loop over and merge if needed\n",
    "for run in sorted_runs: \n",
    "    print('Merging stacks in run: ' + run_dict[run])\n",
    "    run_dir = os.path.join(out_experiment_path, run_dict[run], 'raw')\n",
    "    this_stack_dirs = next(os.walk(run_dir))[1]\n",
    "    existing_stack_dirs = next(os.walk(merged_experiment_path))[1]\n",
    "    for stack_dir in this_stack_dirs:\n",
    "        # Get channel ID and jump\n",
    "        channel_id = extract_channel_id(stack_dir)\n",
    "        channel_jump = channel_jumps[channel_id]\n",
    "        \n",
    "        # Setup the stack directories \n",
    "        dest_dir_long = os.path.join(merged_experiment_path,stack_dir,'Long')\n",
    "        dest_dir_long_mips = os.path.join(merged_experiment_path,stack_dir,'Long', 'MIPs')\n",
    "        dest_dir_short = os.path.join(merged_experiment_path,stack_dir,'Short')\n",
    "        dest_dir_short_mips = os.path.join(merged_experiment_path,stack_dir,'Short', 'MIPs')\n",
    "        src_dict = os.path.join(run_dir,stack_dir)\n",
    "        if not os.path.isdir(dest_dir_long):\n",
    "            os.makedirs(dest_dir_long)\n",
    "            os.makedirs(dest_dir_short)\n",
    "            os.makedirs(dest_dir_long_mips)\n",
    "            os.makedirs(dest_dir_short_mips)\n",
    "            \n",
    "        if stack_dir not in existing_stack_dirs: # If this stack is the first one, copy all the files\n",
    "            src_dict = os.path.join(run_dir,stack_dir)\n",
    "            for f in os.listdir(src_dict):\n",
    "                f_path = os.path.join(src_dict,f)\n",
    "                if os.path.isfile(f_path):\n",
    "                    f_base = os.path.splitext(f)[0]\n",
    "                    f_mip = os.path.join(src_dict, 'MIPs', 'MIP_' + f_base + '.png')\n",
    "                    if 'Long' in f:\n",
    "                        shutil.copy2(f_path, os.path.join(dest_dir_long,f))\n",
    "                        shutil.copy2(f_mip, os.path.join(dest_dir_long_mips, 'MIP_' + f_base + '.png'))\n",
    "                    else:\n",
    "                        shutil.copy2(f_path, os.path.join(dest_dir_short,f))\n",
    "                        shutil.copy2(f_mip, os.path.join(dest_dir_short_mips, 'MIP_' + f_base + '.png'))\n",
    "        else:\n",
    "            # Get the files indexed by the timepoints\n",
    "            dest_files_dict = file_timepoint_dict(dest_dir_long)\n",
    "            src_files_dict = file_timepoint_dict(src_dict)\n",
    "            prev_timestamp = sorted(dest_files_dict.keys())[-1]\n",
    "            for time_idx, fname_list in src_files_dict.items():\n",
    "                for fname in fname_list:\n",
    "                    f_base = os.path.splitext(fname)[0]\n",
    "                    file_prefix, file_ext, time_index = get_filename_components(fname)\n",
    "                    f_mip_name = 'MIP_' + f_base + '.png'\n",
    "                    new_time_index = f'{(prev_timestamp + channel_jump + time_index):05}'\n",
    "                    new_file_name = file_prefix + '_' + new_time_index + file_ext\n",
    "                    new_mip_file_name = 'MIP_' + file_prefix + '_' + new_time_index + '.png'\n",
    "                    if 'Long' in fname:\n",
    "                        shutil.copy2(os.path.join(src_dict, fname), os.path.join(dest_dir_long, new_file_name))\n",
    "                        shutil.copy2(os.path.join(src_dict, 'MIPs', f_mip_name), \n",
    "                                     os.path.join(dest_dir_long_mips, new_mip_file_name))\n",
    "                    else:\n",
    "                        shutil.copy2(os.path.join(src_dict, fname), os.path.join(dest_dir_short, new_file_name))\n",
    "                        shutil.copy2(os.path.join(src_dict, 'MIPs', f_mip_name), \n",
    "                                     os.path.join(dest_dir_short_mips, new_mip_file_name))\n",
    "                        \n",
    "print('Merging the stacks is complete!')\n",
    "print('Merged files are here: ' + merged_experiment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.1: Remove the Individual Acqusition Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Deleting the acqusition stack:')\n",
    "for run in run_dirs:\n",
    "    run_dir = os.path.join(out_experiment_path, run)\n",
    "    shutil.rmtree(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Crop the KLB Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from roi_convertor.gen_crops import *\n",
    "import shutil\n",
    "\n",
    "def group_stack_dir(stack_dirs: list[str]) -> dict: \n",
    "    \"\"\"\n",
    "    Groups stack directory names by their stack ID.\n",
    "\n",
    "    Args:\n",
    "        stack_dirs (list[str]): A list of stack directory names.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are the stack IDs (as integers), and the values are lists of\n",
    "              directory names that correspond to that stack ID.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    stack_dict = {}\n",
    "    for stack_dir_name in stack_dirs:\n",
    "        stack_dir_tok = stack_dir_name.split(sep='_')\n",
    "        if len(stack_dir_tok) > 2 and stack_dir_tok[0] == 'stack':\n",
    "            stack_id = int(stack_dir_tok[1])\n",
    "            if stack_id not in stack_dict: \n",
    "                stack_dict[stack_id] = [stack_dir_name]\n",
    "            else:\n",
    "                stack_dict[stack_id].append(stack_dir_name)\n",
    "    return stack_dict\n",
    "    \n",
    "# Initialized again so that this step could be run if Step 3/4 is being skipped \n",
    "out_experiment_path = os.path.join(output_path, os.path.basename(experiment_path))\n",
    "merged_experiment_path = os.path.join(out_experiment_path, 'merged')\n",
    "\n",
    "# Remove cropped directories if there are any\n",
    "cropped_experiment_path = os.path.join(out_experiment_path, 'cropped')\n",
    "if os.path.isdir(cropped_experiment_path):\n",
    "    shutil.rmtree(cropped_experiment_path)\n",
    "\n",
    "# Create cropped directory\n",
    "os.makedirs(cropped_experiment_path)\n",
    "\n",
    "stack_dirs = next(os.walk(merged_experiment_path))[1]\n",
    "\n",
    "stack_dict = group_stack_dir(stack_dirs)\n",
    "\n",
    "stack_crop_dir = {}\n",
    "stack_crop_found = {}\n",
    "for stack_id, channel_dirs in stack_dict.items():\n",
    "    for stack_dir_name in channel_dirs:\n",
    "        cam_type = 'Long'\n",
    "        stack_dir = os.path.join(merged_experiment_path, stack_dir_name, cam_type)\n",
    "        cropbox_path = os.path.join(cropped_experiment_path, 'stack_' + str(stack_id) + '_cropboxes')\n",
    "        \n",
    "        # Create cropbox directory\n",
    "        if not os.path.isdir(cropbox_path):\n",
    "            os.makedirs(cropbox_path)\n",
    "        \n",
    "        # Generate the cropboxes\n",
    "        box_count = gen_cropboxes(stack_dir, cropbox_path)\n",
    "        \n",
    "        # If there is only one box, we can assume the cropping was success\n",
    "        # Save the cropbox and move to the next stack\n",
    "        if box_count == 1:\n",
    "            stack_crop_found[stack_id] = stack_dir\n",
    "            stack_crop_dir[stack_id] = cropbox_path\n",
    "            break\n",
    "        else:\n",
    "            shutil.rmtree(cropbox_path)\n",
    "\n",
    "# Print the crop boxes to be used\n",
    "for stack_id, stack_dir in stack_crop_dir.items():\n",
    "    print('Stack ' + str(stack_id) + ' to be cropped using boxes of: ' + stack_dir)\n",
    "\n",
    "if foreground:\n",
    "    numThreads= 10 #how many threads do you want pyklb to have access\n",
    "else:\n",
    "    numThreads= 5 #how many threads do you want pyklb to have access\n",
    "            \n",
    "# Crop all the stack directories using the cropboxes for each stack\n",
    "for stack_id, channel_dirs in stack_dict.items():\n",
    "    for stack_dir_name in channel_dirs:\n",
    "        for cam_type in ['Long', 'Short']:\n",
    "            stack_dir = os.path.join(merged_experiment_path, stack_dir_name, cam_type)\n",
    "            cropped_image_path = os.path.join(cropped_experiment_path, stack_dir_name+'_cropped', cam_type)\n",
    "            mip_image_path = os.path.join(cropped_experiment_path, stack_dir_name+'_mip', cam_type)\n",
    "            # Create cropped image directory\n",
    "            if not os.path.isdir(cropped_image_path):\n",
    "                os.makedirs(cropped_image_path)\n",
    "                os.makedirs(mip_image_path)\n",
    "            \n",
    "            \n",
    "            if stack_id in stack_crop_dir:\n",
    "                # If cropbox was identified for the stack\n",
    "                # Generate the cropped files\n",
    "                cropbox_path = stack_crop_dir[stack_id]\n",
    "                generate_crops(stack_dir, cropbox_path, cropped_image_path, 0, 0, -1, 150, 1, 1, 'klb', False, numThreads)\n",
    "                visualize_cropboxes(stack_dir, cropbox_path, mip_image_path, 0, 0, -1, 150, numThreads)\n",
    "            else:\n",
    "                # If cropbox was NOT identified for the stack\n",
    "                # Copy over the files\n",
    "                for f in os.listdir(stack_dir):\n",
    "                    f_path = os.path.join(stack_dir,f)\n",
    "                    if os.path.isfile(f_path):\n",
    "                        shutil.copy2(f_path, os.path.join(cropbox_path,f))\n",
    "                \n",
    "print(' ')\n",
    "print(' ')\n",
    "print('Finished Processing Experiment:' + experiment_path)\n",
    "print('Processing Files:' + out_experiment_path)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('Script Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are intended for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_H5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
